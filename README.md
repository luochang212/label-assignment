# DNN 模型聚类特征在线更新方法

> 发展到今天，多塔模型依旧以 ID 类特征为主。我们用多模态模型、大语言模型从业务上下文中提取到的信息，通常不会将 raw data 直接送入模型，而是先将特征 ID 化，接着用 `mmh3` 哈希打散，再送入模型。因此，搜广推工程师经常需要把模型特征 ID 化。

将模型特征 ID 化有很多方法，比如使用分类模型、量化等。但是其中有一种重要到不可忽视的方法，叫 **聚类**。

**ID 特征通过嵌入层与深度模型相连**。在嵌入层，每个聚类 ID 都对应一个可学习的 embedding。如下图，`idx0`, `idx1`, `idx2` ... `idx4` 是索引，它将聚类 ID 索引到对应的 embedding。当一个样本进入时，它会根据 id 号（比如 0 号）去找对应的索引（`idx0`），然后将索引下的 N 维 embedding 取回。嵌入层在有些地方也被称为码本（codebook）

![embedding_layer](/img/embedding_layer.png)

嵌入层中的 embedding 是可学习的，随着模型的训练，索引对应的 embedding 会被反向传播带来的梯度不断更新，这就是 **表示学习** 的过程。

我们观察到，聚类 ID 和 embedding 是绑定的。历史上模型对于这个聚类 ID 的表示学习，都积累在这个聚类 ID 对应的 embedding 上。

这里引出聚类模型的一个问题：**聚类模型的输出是和输入的全集相关的**。什么意思呢？如果聚类模型的输入不同，则输出的簇的大小和形状可能不同，并且用来标识簇的聚类 ID 也可能会被重置。这可要了命了。模型特征每天都在变，如果每次训练，同一个簇都会被映射到不同的聚类 ID 上，那么这个聚类 ID 绑定的 embedding 其实是用来“表示”别的簇的，那么这个 embedding 实际学不到任何东西，甚至会产生反效果。因此，我们需要做一些开发，将簇映射到正确的聚类 ID 上，多塔模型才能够正常运行。

在第二节，我的思路是重新训练，再用匈牙利算法匹配前后两次训练产生的 label.

第三节不做重训练，而是利用聚类中心和 `eps` 邻域开发一种近似方法，将新样本快速归入某个簇中。

本项目的主要内容包括：

1. 使用 `BLIP-2` 模型将图片转为 embedding
    - 服务端代码：见本项目 [blip2_server.py](https://github.com/luochang212/label-assignment/blob/main/server/blip2_server.py) 文件
    - 客户端代码：见 [1.prepare.ipynb](https://github.com/luochang212/label-assignment/blob/main/1.prepare.ipynb) 第五节
2. 使用匈牙利算法建立重训练标签到原标签的映射
    - 开发以 **样本重合率** 为度量的方法
    - 开发以 **类心距离** 为度量的方法
3. 实现一种为 embedding 赋予近似聚类 ID 的方法：最近邻法

## 一、使用 BLIP-2 生成图片 Embedding

为了获取用于聚类的 Embedding，我们用 CIFAR-100 数据集作为图片来源，然后用 BLIP-2 模型生成图片的 Embedding。

Huggingface: [Salesforce/blip2-opt-2.7b](https://huggingface.co/Salesforce/blip2-opt-2.7b)

> **BLIP-2 (Bootstrapping Language-Image Pre-training 2)** 是 Salesforce 研究院于 2023 年提出的多模态模型。它由三部分组成：
> 
> - 图像编码器（类似 CLIP 的视觉模型）：用于提取图像特征
> - 查询变换器（Q-Former）：作为连接图像与文本的桥梁
> - 大型语言模型（LLM，如 OPT-2.7B）：用于生成文本 
> 
> BLIP-2 训练时，冻结图像编码器和大语言模型的参数，仅优化 Q-Former，这样既能充分利用已有的单模态能力，又能有效提升图文模型的交互效率。Q-Former 作为连接两个模态的桥梁，通过查询学习将视觉特征转换为与语言模型相兼容的表示，从而实现高效的跨模态对齐。


1. 下载 CIFAR-100 数据集
2. 下载 BLIP-2 模型文件
3. 计算图片 Embedding
4. 验证 BLIP-2 服务端代码
5. 开发 BLIP-2 客户端代码


## 二、聚类标签重匹配的两种度量

可以用两种度量做重训练标签到原标签的匹配：

- 样本重合率
- 类心距离

**样本重合率** 的问题是不同标签的样本量不同，这意味着不同标签的敏感性是不同的。如果样本量较高，我们就有较高的置信水平认为该重合率可信；若样本量较低，这种匹配可能不置信。使用 **类心距离** 可以避免这个问题，在整个度量空间中，类心距离不会因标签的不同有所偏倚，是一种相对公平的匹配方法。

因此，类心距离看起来更适合作为度量。但想了想，我还是决定两种方法都尝试一下。因为并非所有聚类都有“类心”。比如，对于物品 ITEM，很可能只有标签，没有类心。这时，样本重合率作为更通用的解决方案，便彰显其价值。下面我们来开发这两种标签重匹配方法。


1. 初次训练与重训练标签
2. 样本重合率
3. 类心距离


## 三、近似赋值：最近邻法

有一种方法工程难度较低，在 DNN 模型允许的情况下，可以这么开发。我把它称为 **最近邻法**。它的原理很简单：给定邻域 `eps`，若新加入 embedding 在某个簇的聚类中心的 `eps` 邻域范围内，则归该簇；否则 embedding 单独建簇。

下面我们把它拆解为具体的开发步骤。

**1）初始化**

1. 用 dbscan 计算每个 embedding 样本的簇 ID
2. 当样本的簇 ID 为 -1 时，说明该样本为离群点，为该样本生成一个与现有簇 ID 不重复的数作为簇 ID
3. 计算每个簇的聚类中心
4. 创建两个 DataFrame：
    - **聚类标签表**：列名为 item_id, embeddings, cluster_id
    - **聚类中心表**：列名为 cluster_id, cluster_center

**2）更新**

1. 当有新 embedding 进入时，计算 embedding 是否在任一簇的聚类中心的 eps 邻域内：
    - 如果在，让 embedding 加入该簇，然后更新该簇的聚类中心
    - 如果不在，创建一个新簇，该 embedding 自己作为聚类中心
2. 更新两个 DataFrame 表，即 聚类标签表 和 聚类中心表

为什么说它是一种近似方法，我画两张图大家就了解了。

**1）错失样本 `X`**

第一张图如下，阴影部分是真正的聚类范围，聚类范围内的所有点都属于该簇。对于后续进入的新样本 `X`，由于我们认为只有聚类中心 `A` 的 `eps` 邻域内的点才是该簇的点，所以 `X` 不会被判定为该簇的点，但实际上 `X` 应该是该簇的点。结果莫名其妙，`X` 生成了一个新簇。

![label_assign_over](/img/label_assign_over.JPG)

**2）聚类中心不属于簇**

聚类中心是由簇内各点求平均得到的，考虑到 dbscan 可能形成任意非凸形状，聚类中心可能不属于该簇，遑论聚类中心的 `eps` 邻域，可能根本就和这个聚类没有关系。如果出现这种情况，那不是近似，而是完全的错误了。

![label_assign_outside](/img/label_assign_outside.JPG)
